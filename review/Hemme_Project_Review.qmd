---
title: Project Review Template 
author: Hayley Hemme
date: "`r file.mtime(knitr::current_input())`"
format: 
  html:
    toc: true
    toc-depth: 3
    number-sections: true
---

# Overview

Title of project: Wastewater Surveillance for SARS-CoV-2 Data Analysis Project

Name of project author(s): Leah Lariscy

Name of project reviewer: Hayley Hemme


# Instructions

Write your comments and feedback below for each section/component of the project. The goal should be to help the author improve their project. Make comments as constructive and actionable as possible. You can provide both criticism and praise.

## Background, Context and Motivation
How well is the context of the project described? Is a comprehensive background, including summary of previous/related work given? Is the project well placed into the context of existing work (including proper referencing of existing work). Is it clear why the project was undertaken and what new information it hopes to provide?

### Feedback and Comments
Overall very clear and background was given. I think that your proposed third paragraph would be great to tie the background up.

### Summary assessment
* strong contextualization and motivation


## Question description
How well and clear are the question(s)/hypotheses the project aims to address described? Is it clear how the questions relate to the data?


### Feedback and Comments

Presented very clearly!

### Summary assessment
* question/hypotheses fully clear


## Data description
How well is the data overall described? Is the source provided? Is a codebook or other meta-information available that makes it clear what the data is? 

Data is clearly described. While the name structure of your variables is very clear, I think it would be useful for readers to see the variables names (as named in R) alongside the description of variable in this section. ex: clinical case seven-day moving average (`case_7dma`) 

### Summary assessment
* source and overall structure of data well explained


## Data wrangling and exploratory analysis
How well is the data cleaned/processed and explored? Are all steps reasonable and well explained? Are alternatives discussed and considered? Are meaningful exploratory results shown (e.g. in the supplementary materials)?

### Feedback and Comments

good job!

### Summary assessment
* essentially no weaknesses in wrangling and exploratory component


## Appropriateness of Analysis
Were the analysis methods appropriate for the data? Was the analysis done properly? Were different components of the analysis (e.g. performance measure, variable selection, data pre-processing, model evaluation) done in the best way possible and explained well?

Methods seemed appropriate; predictor was lagged to account for viral shedding prior case reporting. Variables selected were reasonable.

### Summary assessment
* strong and reasonable analysis

## Presentation
How well are results presented? Are tables and figures easy to read and understand? Are the main figures/tables publication level quality? 

### Feedback and Comments

Very nice!

### Summary assessment
* results are very well presented


## Discussion/Conclusions
Are the study findings properly discussed? Are strengths and limitations acknowledged? Are findings interpreted properly?

### Feedback and Comments

Missing.

### Summary assessment
* major parts of discussion missing or wrong 


## Further comments

Hi Leah. I accidentally closed out of the file containing my feedback as I ran through your project, but I think that this covers everything I found.

The biggest issue I ran into was that your files did not run independently of each other. For the most part, this was only an issue when running code chucks for that contained `test dates`. I think that perhaps the best way to resolve this issue would to simply load this file into every data frame. However, it seems like your files might have been intended to run one after another. I would be sure to talk about this in you `readme` file if this was the intention. While running the files sequentially did resolve the issue of code chucks calling `test dates`, I did encounter an issue due this... in 6_AssayPos_TestPos_model.Rmd incorrectly calls on a workflow object from another model.

Additionally, I would suggest to using unique names for object/ vectors created by different models I think this is especially important when so much of your code is identical in structure across files. I think the most notable ones were the `aug_x`, and `rsme`, and `rsq`. 

Also, I could not get the null models to run in any of the files.


# Overall project content evaluation
Evaluate overall features of the project  by filling in the sections below.


## Structure
### Feedback and Comments

There were several files that were no longer needed, however these were clearly labeled. 

### Summary assessment
* well structured


## Documentation 
How well is the project documented? Are you able to understand each step of the whole analysis, each decision that was made, and each line of code? Is enough information provided as comments in code or as part of Rmd files? 

### Feedback and Comments

Overall, very well documented.

### Summary assessment
* fully and well documented


## Reproducibility
Are all results fully reproducible? Is documentation provided which clearly explains how to reproduce things, and does it work without the need for any manual intervention? Are you able to re-run the whole analysis without having to do manual interventions/edits?

### Feedback and Comments

As far as reproduciblity, I ran into issues with the files running not running indepedently of each other... (as described previously) 


### Summary assessment
* small parts not reproducible or required manual intervention 


## Thoroughness
How thorough was the overall study? Were alternatives (e.g. different ways of processing the data or different models) considered? Were alternatives discussed? Were the questions/hypotheses fully and thoroughly addressed?

Alternatives were not discussed, however, methods and analysis seemed thorough enough to investigate the hypothesis.

### Summary assessment
* strong level of thorougness






